{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf32b705-883a-40b1-9594-fe0afd8d3dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import peakutils as pkuts\n",
    "from scipy import fftpack\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.fft import fft, fftfreq\n",
    "# from matplotlib.offsetbox import AnchoredOffsetbox\n",
    "import datetime as datetime\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import ctypes\n",
    "import seaborn as sns\n",
    "import glob\n",
    "# import imufusion\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54e860e9-fee6-46b2-b9ef-b5575c865c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengthFlag = 0\n",
    "\n",
    "def zipper_data(dat_sleep):\n",
    "    \"\"\"\n",
    "    This function adds a new line to a DataFrame by dropping certain columns, renaming columns, and concatenating DataFrames.\n",
    "    @param dat_sleep - the original DataFrame\n",
    "    @return a new DataFrame with added lines\n",
    "    \"\"\"\n",
    "    df1 = dat_sleep.drop(columns={'XL_X2','XL_Y2','XL_Z2','G_X2','G_Y2','G_Z2'})\n",
    "    df2 = dat_sleep.drop(columns={'XL_X','XL_Y','XL_Z','G_X','G_Y','G_Z'})\n",
    "    df2 = df2.rename(columns={'XL_X2':'XL_X','XL_Y2':'XL_Y','XL_Z2':'XL_Z','G_X2':'G_X','G_Y2':'G_Y','G_Z2':'G_Z'})\n",
    "    lenOfFile = len(dat_sleep)\n",
    "\n",
    "    df = pd.DataFrame(columns=[\"XL_X\", \"XL_Y\", \"XL_Z\", \"G_X\", \"G_Y\", \"G_Z\", \"Temperature\", \"Voltage\", \"Packet\"])\n",
    "    for i in tqdm(range(0, lenOfFile)):\n",
    "        df = pd.concat([df, pd.DataFrame([df1.iloc[i]])])\n",
    "        df = pd.concat([df, pd.DataFrame([df2.iloc[i]])])\n",
    "\n",
    "    return df\n",
    "\n",
    "def extrapolate_time(data, sampling_frequency, num_extrapolated_points):\n",
    "    \"\"\"\n",
    "    This function extrapolates time values based on the sampling frequency provided.\n",
    "    @param data - The input data, which can be a pandas DataFrame or a list.\n",
    "    @param sampling_frequency - The frequency at which the data is sampled.\n",
    "    @param num_extrapolated_points - The number of points to extrapolate.\n",
    "    @return A list of extrapolated timestamps.\n",
    "    \"\"\"\n",
    "    \"\"\"Extrapolates time values based on the sampling frequency.\"\"\"\n",
    "\n",
    "    # Convert data to a pandas DataFrame if it's not already\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        data = pd.DataFrame(data)\n",
    "\n",
    "    # Calculate the time interval between samples\n",
    "    time_interval = 1 / sampling_frequency\n",
    "\n",
    "    # Get the last timestamp in the data\n",
    "    first_timestamp = data.index[0]\n",
    "\n",
    "    # Generate extrapolated timestamps\n",
    "    extrapolated_timestamps = [first_timestamp + timedelta(seconds=(i + 1) * time_interval) \n",
    "                               for i in range(num_extrapolated_points)]\n",
    "\n",
    "    return extrapolated_timestamps\n",
    "\n",
    "def data_processing(dat_lo, hexdat_lo):\n",
    "    \"\"\"\n",
    "    Process the data from the input dat_lo and hexdat_lo to create a new dataframe dat_sleep.\n",
    "    @param dat_lo - the input data frame\n",
    "    @param hexdat_lo - the hex data frame\n",
    "    @param date - the date in the format MMDDYYYY\n",
    "    @return dat_sleep - the processed data frame\n",
    "    \"\"\"\n",
    "    # print(dat_lo)\n",
    "    # print(hexdat_lo)\n",
    "    # Refer to the website: https://github.com/adafruit/Adafruit_LSM6DS/blob/master/Adafruit_LSM6DS.cpp\n",
    "    # Depends on the configuration of IMU on CCS\n",
    "    # dat_lo = dat_lo[0:10]\n",
    "    dat_lo = dat_lo.assign(Temperature = np.nan, Voltage = np.nan) # adding 2 new columns temp and voltage\n",
    "\n",
    "    # scale ranges for converting hexadecimal data to physical units\n",
    "    XL_scale_range_2g = 0.061\n",
    "    XL_scale_range_4g = 0.122\n",
    "    G_scale_range_1000dps = 35\n",
    "    G_scale_range_2000dps = 70\n",
    "    print(\"Added temp and voltage columns\")\n",
    "    lengthFlag = 0\n",
    "\n",
    "    print(\"Starting to convert hex to float\")\n",
    "    # Convert hex to float of acceleration and angular velocity for local data\n",
    "    for k, ele in tqdm(enumerate(hexdat_lo)): # k: count; ele: item; local data\n",
    "        # print(f'index: {k}')\n",
    "        # print(ele)\n",
    "        if len(ele) == 12: # Only select those that have the correct length (12 for motility)\n",
    "            lengthFlag = 0\n",
    "            vlist=[]\n",
    "            for i in range(0, 6):\n",
    "                n = i*2 + 2\n",
    "                value = ''.join(['0x', ele[n-2], ele[n-1]])\n",
    "                hvalue = int(value, 16)\n",
    "                convert_value = ctypes.c_int16(hvalue).value\n",
    "                if i <= 2:\n",
    "                    vlist.append(round(float(convert_value)*XL_scale_range_4g/1000, 2))\n",
    "                else:\n",
    "                    vlist.append(round(float(convert_value)*G_scale_range_1000dps/1000, 2))\n",
    "            # dat_lo.loc[k, 'Message'] = vlist\n",
    "            dat_lo.Message[k] = vlist\n",
    "\n",
    "        elif len(ele) == 13: # Only select those that have the correct length (13 for additional device motility)\n",
    "            vlist=[]\n",
    "            lengthFlag = 0\n",
    "            for i in range(0, len(hexdat_lo)):\n",
    "                hexdat_lo[i] = hexdat_lo[i][1:13] # To remove '00' in the front\n",
    "\n",
    "            for i in range(0, 6):\n",
    "                n = i*2 + 2\n",
    "                value = ''.join(['0x', ele[n-2], ele[n-1]])\n",
    "                hvalue = int(value, 16)\n",
    "                convert_value = ctypes.c_int16(hvalue).value\n",
    "                if i <= 2:\n",
    "                    vlist.append(round(float(convert_value)*XL_scale_range_4g/1000, 2))\n",
    "                else:\n",
    "                    vlist.append(round(float(convert_value)*G_scale_range_1000dps/1000, 2))\n",
    "            # dat_lo.loc[k, 'Message'] = vlist\n",
    "            dat_lo.Message[k] = vlist\n",
    "\n",
    "        elif len(ele) == 24: # Only select those that have the correct length (12 for 2 * motility)\n",
    "            lengthFlag = 1\n",
    "            vlist=[]\n",
    "            first_ele = ele[0:12]\n",
    "            second_ele = ele[12:24]\n",
    "            # print(first_ele)\n",
    "\n",
    "            for i in range(0, 6):\n",
    "                n = i*2 + 2\n",
    "                value = ''.join(['0x', first_ele[n-2], first_ele[n-1]])\n",
    "                hvalue = int(value, 16)\n",
    "                convert_value = ctypes.c_int16(hvalue).value\n",
    "                if i <= 2:\n",
    "                    vlist.append(round(float(convert_value)*XL_scale_range_4g/1000, 2))\n",
    "                else:\n",
    "                    vlist.append(round(float(convert_value)*G_scale_range_1000dps/1000, 2))\n",
    "\n",
    "            for i in range(0, 6):\n",
    "                n = i*2 + 2\n",
    "                value = ''.join(['0x', second_ele[n-2], second_ele[n-1]])\n",
    "                hvalue = int(value, 16)\n",
    "                convert_value = ctypes.c_int16(hvalue).value\n",
    "                if i <= 2:\n",
    "                    vlist.append(round(float(convert_value)*XL_scale_range_4g/1000, 2))\n",
    "                else:\n",
    "                    vlist.append(round(float(convert_value)*G_scale_range_1000dps/1000, 2))\n",
    "            \n",
    "            # print(f'msg: {vlist}')\n",
    "            dat_lo.Message[k] = vlist\n",
    "            \n",
    "        elif len(ele) == 4: # length 4 is for voltage/temperature\n",
    "            dat_lo.Message[k] = 'NaN'\n",
    "            for i in range(0, 2):\n",
    "                n = i*2 + 2\n",
    "                value = ''.join(['0x', ele[n-2], ele[n-1]])\n",
    "                hvalue = int(value, 16)\n",
    "                convert_value = ctypes.c_int16(hvalue).value\n",
    "                if i == 0:\n",
    "                #   vlist.append(float((convert_value/1000)))\n",
    "                    dat_lo.Voltage[k] = float((convert_value/1000))\n",
    "                else:\n",
    "                #  vlist.append(float(convert_value))\n",
    "                    dat_lo.Temperature[k] = float(convert_value)\n",
    "\n",
    "        else:\n",
    "            #print('Line Error!'+str(k))\n",
    "            #print(ele)\n",
    "            vlist = [] #add empty list on error\n",
    "    print(\"finished converting hex to float\")\n",
    "\n",
    "    if lengthFlag == 0:\n",
    "        print(\"Length flag is 0\")\n",
    "        dat_lo[['XL_X', 'XL_Y', 'XL_Z', 'G_X', 'G_Y', 'G_Z']] = np.nan\n",
    "        dat_lo = dat_lo[dat_lo['Message'].notna()]\n",
    "        dat_lo[['XL_X', 'XL_Y', 'XL_Z', 'G_X', 'G_Y', 'G_Z']] = pd.DataFrame(dat_lo['Message'].tolist(), index=dat_lo.index)\n",
    "        dat_sleep = pd.DataFrame(dat_lo, columns=[\"XL_X\", \"XL_Y\", \"XL_Z\", \"G_X\", \"G_Y\", \"G_Z\", \"Temperature\", \"Voltage\", \"Packet\"])\n",
    "        dat_sleep.loc[:,['Temperature', 'Voltage']] = dat_sleep.loc[:,['Temperature', 'Voltage']].ffill().bfill()\n",
    "        dat_sleep = dat_sleep[dat_sleep['XL_X'].notna()]\n",
    "        # print(dat_sleep)\n",
    "\n",
    "    elif lengthFlag == 1:\n",
    "        print(\"Length flag is 1\")\n",
    "        print(dat_lo)\n",
    "        print(dat_lo.Message)\n",
    "        dat_lo.loc[:,['Temperature', 'Voltage']] = dat_lo.loc[:,['Temperature', 'Voltage']].ffill().bfill()\n",
    "        dat_lo['Message'] = dat_lo['Message'].apply(lambda x: x if x != 'NaN' else np.nan)\n",
    "        dat_lo = dat_lo[dat_lo['Message'].notna()]\n",
    "        print(dat_lo)\n",
    "        dat_lo[['XL_X', 'XL_Y', 'XL_Z', 'G_X', 'G_Y', 'G_Z', 'XL_X2', 'XL_Y2', 'XL_Z2', 'G_X2', 'G_Y2', 'G_Z2']] = np.nan\n",
    "        print(dat_lo)\n",
    "        dat_lo.loc[:,['Temperature', 'Voltage']] = dat_lo.loc[:,['Temperature', 'Voltage']].ffill().bfill()\n",
    "        dat_lo = dat_lo.dropna(subset=['Message'])\n",
    "        dat_lo[['XL_X', 'XL_Y', 'XL_Z', 'G_X', 'G_Y', 'G_Z', 'XL_X2', 'XL_Y2', 'XL_Z2', 'G_X2', 'G_Y2', 'G_Z2']] = pd.DataFrame(dat_lo['Message'].tolist(), index=dat_lo.index)\n",
    "        dat_lo = dat_lo[dat_lo['Message'].notna()]\n",
    "        dat_sleep = pd.DataFrame(dat_lo, columns=[\"XL_X\", \"XL_Y\", \"XL_Z\", \"G_X\", \"G_Y\", \"G_Z\", 'XL_X2', 'XL_Y2', 'XL_Z2', 'G_X2', 'G_Y2', 'G_Z2', \"Temperature\", \"Voltage\", \"Packet\"])\n",
    "        print(dat_sleep)\n",
    "        dat_sleep = zipper_data(dat_sleep)\n",
    "    return dat_sleep\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def detect_sample_frequency(sample):\n",
    "    \"\"\"\n",
    "    Detect the frequency of the given sample data.\n",
    "    @param sample - The sample data for which frequency needs to be detected.\n",
    "    @return The inferred frequency of the sample data.\n",
    "    \"\"\"\n",
    "    # s = sample.Time\n",
    "    # print(s)\n",
    "    # fs = sample.head(n=100)\n",
    "    fs = np.diff(sample['Time'].values).min()\n",
    "    print(fs)\n",
    "    return fs\n",
    "\n",
    "def convert_raw_data(file):\n",
    "    \"\"\"\n",
    "    file (input, python list):  list of txt file names with the IMU data\n",
    "    dat (output, pd DataFrame): table with columns Time, MISC, Packet, Message, RSSI\n",
    "    hexdat (output, pd DataFrame): IMU binary data convered to hexadecimal \n",
    "    date (otuput, datetime): date in the format MMDDYYYY\n",
    "\n",
    "    Time: In format HH:MM:SS.MS\n",
    "    MISC: Type of data, f is for voltage, e for temperature and 6 for motility ??\n",
    "    Packet: Gives the packet number\n",
    "    Message: This is in bits\n",
    "    RSSI: Received Signal Strength Indicator, measure that represents the relative quality level of a Bluetooth signal received on a device in decibels-milliwatts (dBm).\n",
    "    \"\"\"\n",
    "\n",
    "    # arranging the data in a readable format as a pd variable\n",
    "    header = 0\n",
    "    dat = pd.read_csv(file, header = header, dtype = str, delimiter = '|', names = ['Time','MISC','Packet','Message','RSSI'])\n",
    "    dat = dat[~dat.RSSI.str.contains('error')] # excludes any error messages when the device is out of range\n",
    "    # dat = dat[dat.MISC.str.contains('f|e|6')] # To keep voltage, temperature and motility data only\n",
    "    dat = dat.reset_index(drop=True)\n",
    "    dat['timedelta'] = pd.to_timedelta(dat['Time'])\n",
    "    # print(dat)\n",
    "\n",
    "    # test\n",
    "    # dat = dat[683333:1514188]\n",
    "    # dat = dat[dat.MISC == ' 0e '] # local\n",
    "    # print(dat)\n",
    "    \n",
    "    # decoding the message from bits to hex\n",
    "    dat_col = dat.Message\n",
    "    dat_col = dat_col.str.strip()\n",
    "    hexdat = dat_col.str.split(' ') \n",
    "    # print(hexdat)\n",
    "\n",
    "    return dat, hexdat\n",
    "    # return dat, hexdat, fs\n",
    "\n",
    "def create_folder_if_doesnt_exist(folder):\n",
    "    \"\"\"\n",
    "    Create a folder if it doesn't exist.\n",
    "    @param folder - The folder to create.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "def output_single_file_of_unprocessed_data(filelist, start_date):\n",
    "    if filelist == []:\n",
    "        print('No files found')\n",
    "        return\n",
    "    \n",
    "    elif len(filelist) == 1:\n",
    "        data, hexdata = convert_raw_data(filelist[0])\n",
    "    \n",
    "    else:\n",
    "        appended_data = []\n",
    "        appended_hexdata = []\n",
    "        for file in sorted(filelist):\n",
    "            data, hexdata = convert_raw_data(file)\n",
    "            print(data)\n",
    "            appended_data.append(data)\n",
    "            appended_hexdata.append(hexdata)\n",
    "\n",
    "        data = pd.concat(appended_data).reset_index(drop=True)\n",
    "        hexdata = pd.concat(appended_hexdata).reset_index(drop=True)\n",
    "\n",
    "    # data = data[0:10]\n",
    "    # hexdata = hexdata[0:10]\n",
    "    print(data)\n",
    "    data['timediff'] = data['timedelta'].diff()\n",
    "    data['timediff'] = data['timediff'].dt.total_seconds()*1000\n",
    "    data['NewDay'] = 0 # create a new column for the day\n",
    "    day = 0 # reset the day counter\n",
    "\n",
    "    print(\"Data with daytime difference being converted\")\n",
    "    for i, row in tqdm(data.iterrows(), total=len(data)):\n",
    "        if row['timediff']< 0:\n",
    "            day += 1\n",
    "            data.loc[i, 'NewDay'] = day\n",
    "        else:\n",
    "            data.loc[i, 'NewDay'] = day\n",
    "\n",
    "    print(f'Number of days in dataset: {day}')\n",
    "    print(data)\n",
    "    \n",
    "    data['Date'] = start_date + pd.to_timedelta(data['NewDay'], unit='d')\n",
    "    data['Timestamp'] = data['Date'] + data['timedelta']\n",
    "    data.set_index('Timestamp', inplace=True)\n",
    "    # data.index = data['Timestamp']\n",
    "    fs = data['timediff'].median()/1000\n",
    "    data.drop(columns=['Time', 'timedelta', 'timediff', 'NewDay', 'Date'], inplace=True)\n",
    "    print(data)\n",
    "    return data, hexdata, fs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aa66314-ec96-44c9-92fd-1a4e304eb799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Time  MISC   Packet                                 Message  \\\n",
      "0       08:35:26.300    0e    54991    02 12 ff d2 e0 50 00 0f ff f7 ff ef     \n",
      "1       08:35:26.300    0e    54992    02 14 ff d8 e0 75 00 0f 00 07 ff f0     \n",
      "2       08:35:26.300    0e    54993    02 18 ff cb e0 8f 00 0f 00 0d ff f0     \n",
      "3       08:35:26.300    0e    54994    02 11 ff da e0 95 00 0f 00 0d ff ef     \n",
      "4       08:35:26.300    0e    54995    02 24 ff e0 e0 8c 00 10 00 0a ff f0     \n",
      "...               ...   ...      ...                                     ...   \n",
      "375787  09:35:45.908    0e    45415    10 d6 ed 03 13 72 ff fb ff f7 00 38     \n",
      "375788  09:35:45.908    0e    45416    10 e2 ec e3 13 2e 00 07 00 32 00 6b     \n",
      "375789  09:35:45.908    0e    45417    10 a9 ec da 13 4b 00 00 00 42 00 7f     \n",
      "375790  09:35:45.908    0e    45418    10 67 ec c1 13 8d ff f7 00 35 00 54     \n",
      "375791  09:35:45.952    0e    45419    10 68 ec d1 13 ec ff fc 00 1e ff e7     \n",
      "\n",
      "         RSSI              timedelta  \n",
      "0         -42 0 days 08:35:26.300000  \n",
      "1         -42 0 days 08:35:26.300000  \n",
      "2         -42 0 days 08:35:26.300000  \n",
      "3         -43 0 days 08:35:26.300000  \n",
      "4         -43 0 days 08:35:26.300000  \n",
      "...       ...                    ...  \n",
      "375787    -58 0 days 09:35:45.908000  \n",
      "375788    -58 0 days 09:35:45.908000  \n",
      "375789    -58 0 days 09:35:45.908000  \n",
      "375790    -58 0 days 09:35:45.908000  \n",
      "375791    -59 0 days 09:35:45.952000  \n",
      "\n",
      "[375792 rows x 6 columns]\n",
      "Data with daytime difference being converted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 375792/375792 [03:55<00:00, 1597.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of days in dataset: 0\n",
      "                 Time  MISC   Packet                                 Message  \\\n",
      "0       08:35:26.300    0e    54991    02 12 ff d2 e0 50 00 0f ff f7 ff ef     \n",
      "1       08:35:26.300    0e    54992    02 14 ff d8 e0 75 00 0f 00 07 ff f0     \n",
      "2       08:35:26.300    0e    54993    02 18 ff cb e0 8f 00 0f 00 0d ff f0     \n",
      "3       08:35:26.300    0e    54994    02 11 ff da e0 95 00 0f 00 0d ff ef     \n",
      "4       08:35:26.300    0e    54995    02 24 ff e0 e0 8c 00 10 00 0a ff f0     \n",
      "...               ...   ...      ...                                     ...   \n",
      "375787  09:35:45.908    0e    45415    10 d6 ed 03 13 72 ff fb ff f7 00 38     \n",
      "375788  09:35:45.908    0e    45416    10 e2 ec e3 13 2e 00 07 00 32 00 6b     \n",
      "375789  09:35:45.908    0e    45417    10 a9 ec da 13 4b 00 00 00 42 00 7f     \n",
      "375790  09:35:45.908    0e    45418    10 67 ec c1 13 8d ff f7 00 35 00 54     \n",
      "375791  09:35:45.952    0e    45419    10 68 ec d1 13 ec ff fc 00 1e ff e7     \n",
      "\n",
      "         RSSI              timedelta  timediff  NewDay  \n",
      "0         -42 0 days 08:35:26.300000       NaN       0  \n",
      "1         -42 0 days 08:35:26.300000       0.0       0  \n",
      "2         -42 0 days 08:35:26.300000       0.0       0  \n",
      "3         -43 0 days 08:35:26.300000       0.0       0  \n",
      "4         -43 0 days 08:35:26.300000       0.0       0  \n",
      "...       ...                    ...       ...     ...  \n",
      "375787    -58 0 days 09:35:45.908000      43.0       0  \n",
      "375788    -58 0 days 09:35:45.908000       0.0       0  \n",
      "375789    -58 0 days 09:35:45.908000       0.0       0  \n",
      "375790    -58 0 days 09:35:45.908000       0.0       0  \n",
      "375791    -59 0 days 09:35:45.952000      44.0       0  \n",
      "\n",
      "[375792 rows x 8 columns]\n",
      "                         MISC   Packet  \\\n",
      "Timestamp                                \n",
      "2025-07-02 08:35:26.300   0e    54991    \n",
      "2025-07-02 08:35:26.300   0e    54992    \n",
      "2025-07-02 08:35:26.300   0e    54993    \n",
      "2025-07-02 08:35:26.300   0e    54994    \n",
      "2025-07-02 08:35:26.300   0e    54995    \n",
      "...                       ...      ...   \n",
      "2025-07-02 09:35:45.908   0e    45415    \n",
      "2025-07-02 09:35:45.908   0e    45416    \n",
      "2025-07-02 09:35:45.908   0e    45417    \n",
      "2025-07-02 09:35:45.908   0e    45418    \n",
      "2025-07-02 09:35:45.952   0e    45419    \n",
      "\n",
      "                                                        Message   RSSI  \n",
      "Timestamp                                                               \n",
      "2025-07-02 08:35:26.300   02 12 ff d2 e0 50 00 0f ff f7 ff ef      -42  \n",
      "2025-07-02 08:35:26.300   02 14 ff d8 e0 75 00 0f 00 07 ff f0      -42  \n",
      "2025-07-02 08:35:26.300   02 18 ff cb e0 8f 00 0f 00 0d ff f0      -42  \n",
      "2025-07-02 08:35:26.300   02 11 ff da e0 95 00 0f 00 0d ff ef      -43  \n",
      "2025-07-02 08:35:26.300   02 24 ff e0 e0 8c 00 10 00 0a ff f0      -43  \n",
      "...                                                         ...    ...  \n",
      "2025-07-02 09:35:45.908   10 d6 ed 03 13 72 ff fb ff f7 00 38      -58  \n",
      "2025-07-02 09:35:45.908   10 e2 ec e3 13 2e 00 07 00 32 00 6b      -58  \n",
      "2025-07-02 09:35:45.908   10 a9 ec da 13 4b 00 00 00 42 00 7f      -58  \n",
      "2025-07-02 09:35:45.908   10 67 ec c1 13 8d ff f7 00 35 00 54      -58  \n",
      "2025-07-02 09:35:45.952   10 68 ec d1 13 ec ff fc 00 1e ff e7      -59  \n",
      "\n",
      "[375792 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############################\n",
    "\n",
    "\n",
    "# --- PARAMETERS ---\n",
    "study_date   = '07022025'\n",
    "data_folder  = r'C:\\Users\\krisf\\OneDrive\\Desktop\\UROP SU25\\Ceara sleep detection\\Modified Data'\n",
    "raw_dir      = os.path.join(data_folder, 'raw', study_date)\n",
    "output_dir   = os.path.join(data_folder, 'processed'+study_date)\n",
    "\n",
    "# --- FIND ALL .TXT FILES FOR THIS STUDY DATE ---\n",
    "filelist = glob.glob(os.path.join(raw_dir, '*.txt'))\n",
    "\n",
    "# --- SPLIT RAW_DIR INTO FOLDER & “FILENAME” (if still needed) ---\n",
    "input_folder, input_filename = os.path.split(raw_dir)\n",
    "\n",
    "# --- PARSE THE STUDY DATE ---\n",
    "# Note: format is YYYYMMDD\n",
    "start_date = datetime.strptime(study_date, '%m%d%Y')\n",
    "\n",
    "chunksize = 10000\n",
    "\n",
    "# --- PROCESS & WRITE OUT ---\n",
    "data, hexdata, fs = output_single_file_of_unprocessed_data(filelist, start_date)\n",
    "\n",
    "\n",
    "\n",
    "# print(f'Sample frequency estimate of dataset: {fs}')\n",
    "\n",
    "# # Prepare the per-date subfolder under processed/\n",
    "# appended_folder = os.path.join(output_dir, 'appendedNotProcessed', study_date)\n",
    "# os.makedirs(appended_folder, exist_ok=True)\n",
    "\n",
    "# # Write CSVs (pandas accepts Path-like or string paths)\n",
    "# data.to_csv(os.path.join(appended_folder, f'{study_date}_data.csv'), index=False)\n",
    "# hexdata.to_csv(os.path.join(appended_folder, f'{study_date}_hexdata.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce02994b-5762-45c5-a8de-579f50e7efcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added temp and voltage columns\n",
      "Starting to convert hex to float\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "375792it [06:15, 1001.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished converting hex to float\n",
      "Length flag is 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XL_X</th>\n",
       "      <th>XL_Y</th>\n",
       "      <th>XL_Z</th>\n",
       "      <th>G_X</th>\n",
       "      <th>G_Y</th>\n",
       "      <th>G_Z</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Packet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-07-02 08:35:26.300</th>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.53</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.746</td>\n",
       "      <td>54991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-02 08:35:26.300</th>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.746</td>\n",
       "      <td>54992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-02 08:35:26.300</th>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.746</td>\n",
       "      <td>54993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-02 08:35:26.300</th>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.746</td>\n",
       "      <td>54994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-02 08:35:26.300</th>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.35</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.746</td>\n",
       "      <td>54995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-02 09:35:45.908</th>\n",
       "      <td>0.53</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>1.96</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.976</td>\n",
       "      <td>45415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-02 09:35:45.908</th>\n",
       "      <td>0.53</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3.75</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.976</td>\n",
       "      <td>45416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-02 09:35:45.908</th>\n",
       "      <td>0.52</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.31</td>\n",
       "      <td>4.45</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.976</td>\n",
       "      <td>45417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-02 09:35:45.908</th>\n",
       "      <td>0.51</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.61</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.94</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.976</td>\n",
       "      <td>45418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-02 09:35:45.952</th>\n",
       "      <td>0.51</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>1.05</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2.976</td>\n",
       "      <td>45419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375792 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         XL_X  XL_Y  XL_Z   G_X   G_Y   G_Z  Temperature  \\\n",
       "Timestamp                                                                  \n",
       "2025-07-02 08:35:26.300  0.06 -0.01 -0.99  0.53 -0.32 -0.59         28.0   \n",
       "2025-07-02 08:35:26.300  0.06  -0.0 -0.99  0.53  0.24 -0.56         28.0   \n",
       "2025-07-02 08:35:26.300  0.07 -0.01 -0.98  0.53  0.46 -0.56         28.0   \n",
       "2025-07-02 08:35:26.300  0.06  -0.0 -0.98  0.53  0.46 -0.59         28.0   \n",
       "2025-07-02 08:35:26.300  0.07  -0.0 -0.98  0.56  0.35 -0.56         28.0   \n",
       "...                       ...   ...   ...   ...   ...   ...          ...   \n",
       "2025-07-02 09:35:45.908  0.53 -0.59  0.61 -0.17 -0.32  1.96         41.0   \n",
       "2025-07-02 09:35:45.908  0.53  -0.6   0.6  0.24  1.75  3.75         41.0   \n",
       "2025-07-02 09:35:45.908  0.52  -0.6   0.6  0.00  2.31  4.45         41.0   \n",
       "2025-07-02 09:35:45.908  0.51  -0.6  0.61 -0.32  1.85  2.94         41.0   \n",
       "2025-07-02 09:35:45.952  0.51  -0.6  0.62 -0.14  1.05 -0.88         41.0   \n",
       "\n",
       "                         Voltage   Packet  \n",
       "Timestamp                                  \n",
       "2025-07-02 08:35:26.300    2.746   54991   \n",
       "2025-07-02 08:35:26.300    2.746   54992   \n",
       "2025-07-02 08:35:26.300    2.746   54993   \n",
       "2025-07-02 08:35:26.300    2.746   54994   \n",
       "2025-07-02 08:35:26.300    2.746   54995   \n",
       "...                          ...      ...  \n",
       "2025-07-02 09:35:45.908    2.976   45415   \n",
       "2025-07-02 09:35:45.908    2.976   45416   \n",
       "2025-07-02 09:35:45.908    2.976   45417   \n",
       "2025-07-02 09:35:45.908    2.976   45418   \n",
       "2025-07-02 09:35:45.952    2.976   45419   \n",
       "\n",
       "[375792 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_processing(data, hexdata)\n",
    "data.to_csv(f'{output_dir}/{study_date}_imuprocessed.csv')\n",
    "\n",
    "data\n",
    "###############################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############ PREPROCESSING ##############\n",
    "# folder date\n",
    "# study_date = '20250407'\n",
    "# data_folder = '../data/IMU/'\n",
    "# directory = f'{data_folder}raw/{study_date}/'\n",
    "# filelist = glob.glob(directory+'*.txt')\n",
    "# input_folder, input_filename = os.path.split(directory)\n",
    "# output_folder = f'{data_folder}processed/'\n",
    "# start_date = datetime.strptime(study_date, '%Y%m%d') #which takes in \"MMDDYYYY\" like only US people write date order\n",
    "# chunksize = 10000\n",
    "\n",
    "\n",
    "# ### WRITE STUDY OUTPUT FILES TO A SINGLE CSV AND SETUP FOR PROCESSING ###\n",
    "# data, hexdata, fs = output_single_file_of_unprocessed_data(filelist, start_date)\n",
    "# # print(f'Sample frequency estimate of dataset: {fs}')\n",
    "\n",
    "# ### WRITE TO CSV IF APPLICABLE ###\n",
    "# create_folder_if_doesnt_exist(f'{output_folder}appendedNotProcessed/{study_date}/')\n",
    "# data.to_csv(f'{output_folder}appendedNotProcessed/{study_date}/{study_date}_data.csv')\n",
    "# hexdata.to_csv(f'{output_folder}appendedNotProcessed/{study_date}/{study_date}_hexdata.csv')\n",
    "# # TODO: add in analysis for multiple sensors in one file\n",
    "\n",
    "# #   ## WRITE TO CSV ###\n",
    "# # input_folder, input_filename = os.path.split(file)\n",
    "# # process the message as a function IMU data\n",
    "# create_folder_if_doesnt_exist(f'{output_folder}{study_date}/')\n",
    "\n",
    "# ## BATCH PROCESS CSV ###\n",
    "# # for datChunk in pd.read_csv(f'{output_folder}appendedNotProcessed/{study_date}/{study_date}_data.csv', index_col='datetime', chunksize=chunksize):\n",
    "# #     datChunk.reset_index(inplace=True)\n",
    "# #     dat_col = datChunk.Message\n",
    "# #     dat_col = dat_col.str.strip()\n",
    "# #     hexdata = dat_col.str.split(' ')\n",
    "# # data.to_csv(f'{output_folder}{study_date}/{study_date}_imuprocessed.csv', mode='a', header=False, index=False)\n",
    "\n",
    "# ## NOT BATCH PROCESS CSV ###\n",
    "# data = data_processing(data, hexdata)\n",
    "# data.to_csv(f'{output_folder}{study_date}/{study_date}_imuprocessed.csv')\n",
    "\n",
    "############ ANALYSIS ##############\n",
    "# cols = ['Timestamp', 'XL_X', 'XL_Y', 'XL_Z', 'G_X', 'G_Y', 'G_Z', \"Temperature\", \"Voltage\", \"Packet\"]\n",
    "# data = pd.read_csv(f'{output_folder}{study_date}/{study_date}_imuprocessed.csv')\n",
    "# data.rename(columns={data.columns[0]: 'Timestamp'}, inplace=True)\n",
    "# data['Timestamp'] = pd.to_datetime(data['Timestamp'])\n",
    "# data.set_index('Timestamp', inplace=True)\n",
    "# lowcut_hr = 2\n",
    "# highcut_hr = 22\n",
    "# i=100\n",
    "# data = calculate_euler_angles(data, fs)\n",
    "# print(data)\n",
    "# plot_euler_angles(data, i)\n",
    "# upper_thresh, lower_thresh, piecewise_linear_peaks_outl_rm, piecewise_linear_valleys_outl_rm, angle_w, mov_avg, time_w, peaks, valleys = peak_detection(data, fs)\n",
    "# plot_peak_detection(upper_thresh, lower_thresh, piecewise_linear_peaks_outl_rm, piecewise_linear_valleys_outl_rm, angle_w, mov_avg, time_w, peaks, valleys, i)\n",
    "# print(data)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
